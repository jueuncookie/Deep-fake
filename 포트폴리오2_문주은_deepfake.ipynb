{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "포트폴리오2 문주은 deepfake.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd7tKR387_Ox"
      },
      "source": [
        "#deepfake from cruise\n",
        "\n",
        "[아이언맨](https://www.youtube.com/watch?v=iDM69UEyM3w)\n",
        "\n",
        "- Deep Learning으로 얼굴을 바꾸어 주는 툴로 소스코드는 막아 놓음\n",
        "- 음성은 바꿀 수 있음 (인물의 5초 정도의 음성 녹음 파일이 필요)\n",
        "- A 영상의 인물을 B 인물의 사진 한장으로 바꿔 치기 (눈, 코, 입 주변만)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mOPSUt2-1Z4"
      },
      "source": [
        "[Ai 앵커](https://www.youtube.com/watch?v=5GFt5TAmPfk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68aHLLOL_0PO"
      },
      "source": [
        "# Demo for paper \"First Order Motion Model for Image Animation\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dneSNs8Lvf3_"
      },
      "source": [
        "**Clone repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtkk00xUvide",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a765e298-d8c2-4a80-cbcc-d6251814330b"
      },
      "source": [
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'first-order-model'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 299 (delta 2), reused 2 (delta 0), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (299/299), 72.15 MiB | 13.24 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY6g78UavkK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91413f25-7440-4392-b819-375b111ea432"
      },
      "source": [
        "cd first-order-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/first-order-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTUEsjZ9QK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ea95ec-9430-4cc0-993f-d91ef56243a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtjtDLGsvn22"
      },
      "source": [
        "**Load driving video and source image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cY5U2FlFQa1"
      },
      "source": [
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "source_image = imageio.imread('/content/drive/MyDrive/myface.JPG')\n",
        "#source_image = imageio.imread('02.png')\n",
        "reader = imageio.get_reader('/content/drive/MyDrive/04.mp4')\n",
        "#reader = imageio.get_reader('04.mp4')\n",
        "\n",
        "\n",
        "#Resize image and video to 256x256\n",
        "\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "\n",
        "fps = reader.get_meta_data()['fps']\n",
        "driving_video = []\n",
        "try:\n",
        "    for im in reader:\n",
        "        driving_video.append(im)\n",
        "except RuntimeError:\n",
        "    pass\n",
        "reader.close()\n",
        "\n",
        "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "\n",
        "def display(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = [source]\n",
        "        cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani\n",
        "    \n",
        "\n",
        "HTML(display(source_image, driving_video).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgNySgZ1vtSW"
      },
      "source": [
        "**Create a model and load checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX39V35oGQVm"
      },
      "source": [
        "from demo import load_checkpoints\n",
        "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', \n",
        "                            checkpoint_path='/content/drive/My Drive/vox-cpk.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzZ9DVy5vxEe"
      },
      "source": [
        "**Perform image animation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk2lv7BGLf0L"
      },
      "source": [
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
        "\n",
        "#save resulting video\n",
        "imageio.mimsave('../generated.mp4', [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "#video can be downloaded from /content folder\n",
        "\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}